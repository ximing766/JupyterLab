{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 延后初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习框架无法判断网络的输入维度是什么。 这里的诀窍是框架的延后初始化（defers initialization）， 即直到数据第一次通过模型传递时，框架才会动态地推断出每个层的大小。\n",
    "\n",
    "当使用卷积神经网络时， 由于输入维度（即图像的分辨率）将影响每个后续层的维数， 有了该技术将更加方便。 现在我们在编写代码时无须知道维度是什么就可以设置参数， 这种能力可以大大简化定义和修改模型的任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[net.layers[i].get_weights() for i in range(len(net.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform((2, 20))\n",
    "net(X)\n",
    "[w.shape for w in net.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-单轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",  # 替换为你的 Moonshot AI API Key\n",
    "    # base_url=\"https://api.moonshot.cn/v1\"\n",
    "    base_url = \"http://127.0.0.1:8888/v1\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一些涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。\"},\n",
    "        {\"role\": \"user\", \"content\": \"你好，我叫李雷，1+1 等于多少？\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 单轮对话没有记忆能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"我叫什么名字？\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-多轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import pprint \n",
    "client = OpenAI(\n",
    "    api_key = \"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\", # 在这里将 MOONSHOT_API_KEY 替换为你从 Kimi 开放平台申请的 API Key\n",
    "    # base_url = \"https://api.moonshot.cn/v1\",\n",
    "\tbase_url = \"http://127.0.0.1:8888/v1\"\n",
    ")\n",
    " \n",
    "system_messages = [\n",
    "\t# {\"role\": \"system\", \"content\": \"你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一切涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。\"},\n",
    "\t{\"role\": \"system\", \"content\": \"你是 Kimi， 你擅长中文。\"},\n",
    "]\n",
    "# global messages\n",
    "messages = []\n",
    "# 限制上下文长度\n",
    "def make_messages(input: str, n: int = 20):   \n",
    "\tglobal messages\n",
    "\tmessages.append({\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": input,\t\n",
    "\t})\n",
    " \n",
    "\tnew_messages = []\n",
    "\tnew_messages.extend(system_messages)\n",
    " \n",
    "\tif len(messages) > n:\n",
    "\t\tmessages = messages[-n:]\n",
    " \n",
    "\tnew_messages.extend(messages)\n",
    "\treturn new_messages\n",
    " \n",
    " \n",
    "def chat(input: str) -> str:\n",
    "\tmsg = make_messages(input)\n",
    "\t\n",
    "\tcompletion = client.chat.completions.create(\n",
    "        model=\"moonshot-v1-auto\",\n",
    "        messages=msg,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\tassistant_message = completion.choices[0].message\n",
    "\tmessages.append(assistant_message)\n",
    "\tprint(f\"Kimi: {assistant_message.content}\")\n",
    "\t# return assistant_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat(\"你好，我今年 27 岁。\")\n",
    "time.sleep(1)\n",
    "chat(\"你知道我今年几岁吗？\")\n",
    "time.sleep(1)\n",
    "chat(\"你脾气如何？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kimi Chat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion import Choice\n",
    "from openai import OpenAI, OpenAIError\n",
    "from pprint import pprint\n",
    "from typing import *\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "class KimiChatAssistant:\n",
    "    def __init__(self, api_key, base_url, system_content, model, max_context_length=20, Candidates=1, use_stream=False):\n",
    "        \"\"\"\n",
    "        初始化聊天管理器\n",
    "        :param api_key: OpenAI API 密钥\n",
    "        :param base_url: API 请求的基础 URL\n",
    "        :param system_content: 系统消息内容\n",
    "        :param model: 使用的模型名称\n",
    "        :param max_context_length: 上下文最大长度，默认为 20\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url\n",
    "        )\n",
    "        self.system_messages = [{\"role\": \"system\", \"content\": system_content}]\n",
    "        self.messages = []\n",
    "        self.model = model\n",
    "        self.max_context_length = max_context_length\n",
    "        self.max_attempts = 1    # 最大重试次数\n",
    "        self.use_stream = use_stream\n",
    "        self.Candidates = Candidates\n",
    "        self.finish_reason = None\n",
    "\n",
    "        self.tools = [\n",
    "            {\n",
    "                \"type\": \"builtin_function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\",\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.system_messages + self.messages\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def print_context(self):\n",
    "        print(\"当前上下文:\")\n",
    "        pprint.pprint(self.get_history())\n",
    "\n",
    "    def search_impl(self, arguments):\n",
    "        return arguments\n",
    " \n",
    "\n",
    "    def prepare_messages(self, user_input):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        new_messages = self.system_messages.copy()\n",
    "        \n",
    "        if len(self.messages) > self.max_context_length:\n",
    "            self.messages = self.messages[-self.max_context_length:]\n",
    "        new_messages.extend(self.messages)\n",
    "\n",
    "        return new_messages\n",
    "\n",
    "    def chat_once(self, msg):\n",
    "        messages = msg\n",
    "        for i in range(self.max_attempts):\n",
    "            try:\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                    stream=self.use_stream,\n",
    "                    n=self.Candidates,           # 返回候选\n",
    "                    tools=self.tools,\n",
    "                )\n",
    "                if self.use_stream:\n",
    "                    return completion\n",
    "                assistant_message = completion.choices[0]   # 第一个候选\n",
    "                # self.messages.append(completion.choices[0].message)\n",
    "                return assistant_message\n",
    "            except OpenAIError as e:\n",
    "                print(f\"API 调用失败: {e}\")\n",
    "                if i < self.max_attempts - 1:\n",
    "                    print(f\"正在进行第 {i+1} 次重试...\")\n",
    "                    time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"发生未知错误: {e}\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        return \"抱歉，系统无法提供回复，请稍后再试。\"\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        messages = self.prepare_messages(user_input)\n",
    "        while self.finish_reason is None or self.finish_reason == \"tool_calls\":\n",
    "            # print(\"Kimi 大模型正在联网思考中...\")\n",
    "            choice = self.chat_once(messages)\n",
    "            print(type(choice))\n",
    "            self.finish_reason = choice.finish_reason\n",
    "            if self.finish_reason == \"tool_calls\":  # <-- 判断当前返回内容是否包含 tool_calls\n",
    "                messages.append(choice.message)  # <-- 我们将 Kimi 大模型返回给我们的 assistant 消息也添加到上下文中，以便于下次请求时 Kimi 大模型能理解我们的诉求\n",
    "                for tool_call in choice.message.tool_calls:  # <-- tool_calls 可能是多个，因此我们使用循环逐个执行\n",
    "                    tool_call_name = tool_call.function.name\n",
    "                    tool_call_arguments = json.loads(tool_call.function.arguments)  # <-- arguments 是序列化后的 JSON Object，我们需要使用 json.loads 反序列化一下\n",
    "                    if tool_call_name == \"$web_search\":\n",
    "                        tool_result = self.search_impl(tool_call_arguments)\n",
    "                    else:\n",
    "                        tool_result = f\"Error: unable to find tool by name '{tool_call_name}'\"\n",
    "    \n",
    "                    messages.append({\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"name\": tool_call_name,\n",
    "                        \"content\": json.dumps(tool_result),  \n",
    "                    })\n",
    "        # print(choice.message.content)\n",
    "        self.finish_reason = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.chat.chat_completion.Choice'>\n",
      "<class 'openai.types.chat.chat_completion.Choice'>\n",
      "<class 'openai.types.chat.chat_completion.Choice'>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    use_stream = False\n",
    "    chat_manager = KimiChatAssistant(\n",
    "        api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    "        base_url=\"http://127.0.0.1:8888/v1\",\n",
    "        # base_url = \"https://api.moonshot.cn/v1\",\n",
    "        system_content=\"你是 Kimi， 你只会使用中文进行对话。\",\n",
    "        model=\"moonshot-v1-auto\",\n",
    "        max_context_length= 20,\n",
    "        use_stream = use_stream,\n",
    "        Candidates = 1,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"请输入你的问题(输入 'exit' 退出)：\\n\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        chat_manager.chat(user_input)\n",
    "\n",
    "        \n",
    "        # if use_stream:\n",
    "        #     for chunk in response:\n",
    "        #         delta = chunk.choices[0].delta\n",
    "        #         if delta.content:\n",
    "        #             print(delta.content, end=\"\", flush=True)\n",
    "        #     print(\"\\n\")\n",
    "        #     continue\n",
    "        # print(f\"Kimi: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kimi联网思考 \n",
      "Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='t-web_search-67b00b0198a6', function=Function(arguments='{\"search_result\":{\"search_id\":\"94c9db3467b00b0164481b0001012198\"},\"usage\":{\"total_tokens\":7299}}', name='$web_search'), type='builtin_function')]))\n",
      "Kimi联网思考 \n",
      "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='以下是关于“哪吒2”的一些信息汇总：\\n\\n1. **电影《哪吒2之魔童闹海》**：这是国产动画电影《哪吒之魔童降世》的续作，由饺子导演，已定档2025年大年初一（2025年1月29日）上映。《哪吒之魔童降世》于2019年上映后，拿下了超50亿票房，当前位列中国电影票房总榜第四。《哪吒2》讲述了天劫之后，哪吒、敖丙的灵魂虽保住了，但肉身很快会魂飞魄散。太乙真人打算用七色宝莲给二人重塑肉身，但在重塑肉身的过程中却遇到重重困难，哪吒、敖丙的命运将走向何方？[来源](https://www.ithome.com/0/822/841.htm)\\n\\n2. **票房成绩**：《哪吒之魔童闹海》累计票房（含预售及海外票房）破100亿元，成为中国电影史上首部票房过百亿的影片，同时创造全球单一电影市场最高票房纪录。[来源](https://news.sina.com.cn/zx/2025-02-14/doc-inekmyqz0804477.shtml)\\n\\n3. **海外上映**：《哪吒2》将在北美地区开启特别制式点映，2月14日正式上映。目前预售场次火爆，上座率达90%以上，多个热门场次均已售罄。[来源](https://news.sina.com.cn/zx/2025-02-14/doc-inekmyqz0804477.shtml)\\n\\n4. **书籍相关**：随着电影《哪吒之魔童闹海》登顶全球影史票房榜，电影衍生的正版图书在天猫掀起抢购潮。其中包括《哪吒・三界往事》原创绘本、《魔童闹海艺术设定集》及《敖丙传》等。[来源](https://www.geekpark.net/news/345815)\\n\\n5. **文化影响**：《哪吒2》的成功，不仅体现在其过人的制作水平和引人入胜的故事情节，更在于对中华传统文化的现代理解与继承。它让更多人走进了神话的世界，唤起我们对于传统文化的认知与热爱。[来源](https://www.sohu.com/a/859269063_121956424)\\n\\n这些信息提供了关于《哪吒2》的全面概览，包括电影的上映信息、票房成绩、海外上映情况以及相关书籍和文化影响。', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))\n",
      "以下是关于“哪吒2”的一些信息汇总：\n",
      "\n",
      "1. **电影《哪吒2之魔童闹海》**：这是国产动画电影《哪吒之魔童降世》的续作，由饺子导演，已定档2025年大年初一（2025年1月29日）上映。《哪吒之魔童降世》于2019年上映后，拿下了超50亿票房，当前位列中国电影票房总榜第四。《哪吒2》讲述了天劫之后，哪吒、敖丙的灵魂虽保住了，但肉身很快会魂飞魄散。太乙真人打算用七色宝莲给二人重塑肉身，但在重塑肉身的过程中却遇到重重困难，哪吒、敖丙的命运将走向何方？[来源](https://www.ithome.com/0/822/841.htm)\n",
      "\n",
      "2. **票房成绩**：《哪吒之魔童闹海》累计票房（含预售及海外票房）破100亿元，成为中国电影史上首部票房过百亿的影片，同时创造全球单一电影市场最高票房纪录。[来源](https://news.sina.com.cn/zx/2025-02-14/doc-inekmyqz0804477.shtml)\n",
      "\n",
      "3. **海外上映**：《哪吒2》将在北美地区开启特别制式点映，2月14日正式上映。目前预售场次火爆，上座率达90%以上，多个热门场次均已售罄。[来源](https://news.sina.com.cn/zx/2025-02-14/doc-inekmyqz0804477.shtml)\n",
      "\n",
      "4. **书籍相关**：随着电影《哪吒之魔童闹海》登顶全球影史票房榜，电影衍生的正版图书在天猫掀起抢购潮。其中包括《哪吒・三界往事》原创绘本、《魔童闹海艺术设定集》及《敖丙传》等。[来源](https://www.geekpark.net/news/345815)\n",
      "\n",
      "5. **文化影响**：《哪吒2》的成功，不仅体现在其过人的制作水平和引人入胜的故事情节，更在于对中华传统文化的现代理解与继承。它让更多人走进了神话的世界，唤起我们对于传统文化的认知与热爱。[来源](https://www.sohu.com/a/859269063_121956424)\n",
      "\n",
      "这些信息提供了关于《哪吒2》的全面概览，包括电影的上映信息、票房成绩、海外上映情况以及相关书籍和文化影响。\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    " \n",
    "import os\n",
    "import json\n",
    " \n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion import Choice\n",
    " \n",
    "client = OpenAI(\n",
    "    # base_url=\"https://api.moonshot.cn/v1\",\n",
    "    base_url=\"http://127.0.0.1:8888/v1\",\n",
    "    api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    ")\n",
    " \n",
    " \n",
    "# search 工具的具体实现，这里我们只需要返回参数即可\n",
    "def search_impl(arguments: Dict[str, Any]) -> Any:\n",
    "    \"\"\"\n",
    "    在使用 Moonshot AI 提供的 search 工具的场合，只需要原封不动返回 arguments 即可，\n",
    "    不需要额外的处理逻辑。\n",
    " \n",
    "    但如果你想使用其他模型，并保留联网搜索的功能，那你只需要修改这里的实现（例如调用搜索\n",
    "    和获取网页内容等），函数签名不变，依然是 work 的。\n",
    " \n",
    "    这最大程度保证了兼容性，允许你在不同的模型间切换，并且不需要对代码有破坏性的修改。\n",
    "    \"\"\"\n",
    "    return arguments\n",
    " \n",
    " \n",
    "def chat(messages) -> Choice:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"moonshot-v1-128k\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"builtin_function\",  # <-- 使用 builtin_function 声明 $web_search 函数，请在每次请求都完整地带上 tools 声明\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0]\n",
    " \n",
    " \n",
    "def main():\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"你是 Kimi。\"},\n",
    "    ]\n",
    " \n",
    "    # 初始提问\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"联网搜索哪吒2。\"\n",
    "    })\n",
    " \n",
    "    finish_reason = None\n",
    "    while finish_reason is None or finish_reason == \"tool_calls\":\n",
    "        print(\"Kimi联网思考 \")\n",
    "        choice = chat(messages)\n",
    "        print(choice)\n",
    "        finish_reason = choice.finish_reason\n",
    "        if finish_reason == \"tool_calls\":  # <-- 判断当前返回内容是否包含 tool_calls\n",
    "            messages.append(choice.message)  # <-- 我们将 Kimi 大模型返回给我们的 assistant 消息也添加到上下文中，以便于下次请求时 Kimi 大模型能理解我们的诉求\n",
    "            for tool_call in choice.message.tool_calls:  # <-- tool_calls 可能是多个，因此我们使用循环逐个执行\n",
    "                tool_call_name = tool_call.function.name\n",
    "                tool_call_arguments = json.loads(tool_call.function.arguments)  # <-- arguments 是序列化后的 JSON Object，我们需要使用 json.loads 反序列化一下\n",
    "                if tool_call_name == \"$web_search\":\n",
    "                    tool_result = search_impl(tool_call_arguments)\n",
    "                else:\n",
    "                    tool_result = f\"Error: unable to find tool by name '{tool_call_name}'\"\n",
    " \n",
    "                # 使用函数执行结果构造一个 role=tool 的 message，以此来向模型展示工具调用的结果；\n",
    "                # 注意，我们需要在 message 中提供 tool_call_id 和 name 字段，以便 Kimi 大模型\n",
    "                # 能正确匹配到对应的 tool_call。\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_call_name,\n",
    "                    \"content\": json.dumps(tool_result),  # <-- 我们约定使用字符串格式向 Kimi 大模型提交工具调用结果，因此在这里使用 json.dumps 将执行结果序列化成字符串\n",
    "                })\n",
    "        # else:\n",
    "        #     break\n",
    " \n",
    "    print(choice.message.content)  # <-- 在这里，我们才将模型生成的回复返回给用户\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-工具调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(\n",
    "    api_key = \"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    "    base_url = \"https://api.moonshot.cn/v1\",\n",
    ")\n",
    "\n",
    "tool = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"CodeRunner\",\n",
    "        \"description\": \"代码执行器，支持运行 python 和 javascript 代码\",\n",
    "        \"parameters\": {\n",
    "          \"properties\": {\n",
    "            \"language\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"python\", \"javascript\"]\n",
    "            },\n",
    "            \"code\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"代码写在这里\"\n",
    "            }\n",
    "          },\n",
    "          \"type\": \"object\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。你会为用户提供安全，有帮助，准确的回答。同时，你会拒绝一些涉及恐怖主义，种族歧视，黄色暴力等问题的回答。Moonshot AI 为专有名词，不可翻译成其他语言。\"},\n",
    "        {\"role\": \"user\", \"content\": \"编程判断 3214567 是否是素数。\"}\n",
    "    ],\n",
    "    tools = tool,\n",
    "    temperature=0.3,\n",
    ")\n",
    "print(completion.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion.choices[0].message.tool_calls[0].function.arguments[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
