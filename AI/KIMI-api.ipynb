{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å»¶åŽåˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ·±åº¦å­¦ä¹ æ¡†æž¶æ— æ³•åˆ¤æ–­ç½‘ç»œçš„è¾“å…¥ç»´åº¦æ˜¯ä»€ä¹ˆã€‚ è¿™é‡Œçš„è¯€çªæ˜¯æ¡†æž¶çš„å»¶åŽåˆå§‹åŒ–ï¼ˆdefers initializationï¼‰ï¼Œ å³ç›´åˆ°æ•°æ®ç¬¬ä¸€æ¬¡é€šè¿‡æ¨¡åž‹ä¼ é€’æ—¶ï¼Œæ¡†æž¶æ‰ä¼šåŠ¨æ€åœ°æŽ¨æ–­å‡ºæ¯ä¸ªå±‚çš„å¤§å°ã€‚\n",
    "\n",
    "å½“ä½¿ç”¨å·ç§¯ç¥žç»ç½‘ç»œæ—¶ï¼Œ ç”±äºŽè¾“å…¥ç»´åº¦ï¼ˆå³å›¾åƒçš„åˆ†è¾¨çŽ‡ï¼‰å°†å½±å“æ¯ä¸ªåŽç»­å±‚çš„ç»´æ•°ï¼Œ æœ‰äº†è¯¥æŠ€æœ¯å°†æ›´åŠ æ–¹ä¾¿ã€‚ çŽ°åœ¨æˆ‘ä»¬åœ¨ç¼–å†™ä»£ç æ—¶æ— é¡»çŸ¥é“ç»´åº¦æ˜¯ä»€ä¹ˆå°±å¯ä»¥è®¾ç½®å‚æ•°ï¼Œ è¿™ç§èƒ½åŠ›å¯ä»¥å¤§å¤§ç®€åŒ–å®šä¹‰å’Œä¿®æ”¹æ¨¡åž‹çš„ä»»åŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "net = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[net.layers[i].get_weights() for i in range(len(net.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.random.uniform((2, 20))\n",
    "net(X)\n",
    "[w.shape for w in net.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-å•è½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",  # æ›¿æ¢ä¸ºä½ çš„ Moonshot AI API Key\n",
    "    # base_url=\"https://api.moonshot.cn/v1\"\n",
    "    base_url = \"http://127.0.0.1:8888/v1\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›žç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€äº›æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›žç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"ä½ å¥½ï¼Œæˆ‘å«æŽé›·ï¼Œ1+1 ç­‰äºŽå¤šå°‘ï¼Ÿ\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å•è½®å¯¹è¯æ²¡æœ‰è®°å¿†èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\"}\n",
    "    ],\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-å¤šè½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import time\n",
    "import pprint \n",
    "client = OpenAI(\n",
    "    api_key = \"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\", # åœ¨è¿™é‡Œå°† MOONSHOT_API_KEY æ›¿æ¢ä¸ºä½ ä»Ž Kimi å¼€æ”¾å¹³å°ç”³è¯·çš„ API Key\n",
    "    # base_url = \"https://api.moonshot.cn/v1\",\n",
    "\tbase_url = \"http://127.0.0.1:8888/v1\"\n",
    ")\n",
    " \n",
    "system_messages = [\n",
    "\t# {\"role\": \"system\", \"content\": \"ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›žç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€åˆ‡æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›žç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚\"},\n",
    "\t{\"role\": \"system\", \"content\": \"ä½ æ˜¯ Kimiï¼Œ ä½ æ“…é•¿ä¸­æ–‡ã€‚\"},\n",
    "]\n",
    "# global messages\n",
    "messages = []\n",
    "# é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦\n",
    "def make_messages(input: str, n: int = 20):   \n",
    "\tglobal messages\n",
    "\tmessages.append({\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": input,\t\n",
    "\t})\n",
    " \n",
    "\tnew_messages = []\n",
    "\tnew_messages.extend(system_messages)\n",
    " \n",
    "\tif len(messages) > n:\n",
    "\t\tmessages = messages[-n:]\n",
    " \n",
    "\tnew_messages.extend(messages)\n",
    "\treturn new_messages\n",
    " \n",
    " \n",
    "def chat(input: str) -> str:\n",
    "\tmsg = make_messages(input)\n",
    "\t\n",
    "\tcompletion = client.chat.completions.create(\n",
    "        model=\"moonshot-v1-auto\",\n",
    "        messages=msg,\n",
    "        temperature=0.3,\n",
    "    )\n",
    "\tassistant_message = completion.choices[0].message\n",
    "\tmessages.append(assistant_message)\n",
    "\tprint(f\"Kimi: {assistant_message.content}\")\n",
    "\t# return assistant_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat(\"ä½ å¥½ï¼Œæˆ‘ä»Šå¹´ 27 å²ã€‚\")\n",
    "time.sleep(1)\n",
    "chat(\"ä½ çŸ¥é“æˆ‘ä»Šå¹´å‡ å²å—ï¼Ÿ\")\n",
    "time.sleep(1)\n",
    "chat(\"ä½ è„¾æ°”å¦‚ä½•ï¼Ÿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kimi Chat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, OpenAIError\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "class KimiChatAssistant:\n",
    "    def __init__(self, api_key, base_url, system_content, model, max_context_length=20, Candidates=1, use_stream=False):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–èŠå¤©ç®¡ç†å™¨\n",
    "        :param api_key: OpenAI API å¯†é’¥\n",
    "        :param base_url: API è¯·æ±‚çš„åŸºç¡€ URL\n",
    "        :param system_content: ç³»ç»Ÿæ¶ˆæ¯å†…å®¹\n",
    "        :param model: ä½¿ç”¨çš„æ¨¡åž‹åç§°\n",
    "        :param max_context_length: ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦ï¼Œé»˜è®¤ä¸º 20\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url\n",
    "        )\n",
    "        self.system_messages = [{\"role\": \"system\", \"content\": system_content}]\n",
    "        self.messages = []\n",
    "        self.model = model\n",
    "        self.max_context_length = max_context_length\n",
    "        self.max_attempts = 1    # æœ€å¤§é‡è¯•æ¬¡æ•°\n",
    "        self.use_stream = use_stream\n",
    "        self.Candidates = Candidates\n",
    "\n",
    "        self.tools = [\n",
    "            {\n",
    "                \"type\": \"builtin_function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\",\n",
    "                },\n",
    "            },\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "    def get_history(self):\n",
    "        return self.system_messages + self.messages\n",
    "\n",
    "    def reset_history(self):\n",
    "        self.messages = []\n",
    "\n",
    "    def print_context(self):\n",
    "        print(\"å½“å‰ä¸Šä¸‹æ–‡:\")\n",
    "        pprint.pprint(self.get_history())\n",
    "\n",
    "    def search_impl(self, arguments):\n",
    "        return arguments\n",
    " \n",
    "\n",
    "    def prepare_messages(self, user_input):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        new_messages = self.system_messages.copy()\n",
    "        \n",
    "        if len(self.messages) > self.max_context_length:\n",
    "            self.messages = self.messages[-self.max_context_length:]\n",
    "        new_messages.extend(self.messages)\n",
    "\n",
    "        return new_messages\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        messages = self.prepare_messages(user_input)\n",
    "        for i in range(self.max_attempts):\n",
    "            try:\n",
    "                completion = self.client.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.3,\n",
    "                    stream=self.use_stream,\n",
    "                    n=self.Candidates,           # è¿”å›žå€™é€‰\n",
    "                    tools=self.tools,\n",
    "                )\n",
    "                if self.use_stream:\n",
    "                    return completion\n",
    "                assistant_message = completion.choices[0]   # ç¬¬ä¸€ä¸ªå€™é€‰\n",
    "                self.messages.append(assistant_message.message)\n",
    "                return assistant_message\n",
    "            except OpenAIError as e:\n",
    "                print(f\"API è°ƒç”¨å¤±è´¥: {e}\")\n",
    "                if i < self.max_attempts - 1:\n",
    "                    print(f\"æ­£åœ¨è¿›è¡Œç¬¬ {i+1} æ¬¡é‡è¯•...\")\n",
    "                    time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "                time.sleep(1)\n",
    "                continue\n",
    "\n",
    "        return \"æŠ±æ­‰ï¼Œç³»ç»Ÿæ— æ³•æä¾›å›žå¤ï¼Œè¯·ç¨åŽå†è¯•ã€‚\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kimi: å—¨ï¼ä½ å¥½å‘€ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼ŸðŸŒŸ\n",
      "Kimi: å—¨ï¼å¾ˆé«˜å…´å’Œä½ èŠå¤©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸðŸŒ·\n",
      "Kimi: ä½ å¥½ï¼çœ‹èµ·æ¥ä½ å¿ƒæƒ…ä¸é”™ï¼Œå–œæ¬¢æ‰“æ‹›å‘¼å‘¢ã€‚æœ‰ä»€ä¹ˆç‰¹åˆ«çš„äº‹æƒ…æƒ³è¦å’Œæˆ‘åˆ†äº«å—ï¼Ÿæˆ–è€…æœ‰ä»€ä¹ˆé—®é¢˜éœ€è¦æˆ‘å¸®å¿™è§£ç­”ï¼Ÿ\n",
      "Kimi: å—¨ï¼çœ‹æ¥ä½ å¿ƒæƒ…ä¸é”™ï¼Œå–œæ¬¢é‡å¤æ‰“æ‹›å‘¼å‘¢ã€‚å¦‚æžœæœ‰ä»€ä¹ˆæƒ³è¦èŠçš„æˆ–è€…éœ€è¦å¸®åŠ©çš„åœ°æ–¹ï¼Œéšæ—¶å‘Šè¯‰æˆ‘å“¦ï¼ðŸ˜„\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    use_stream = False\n",
    "    chat_manager = KimiChatAssistant(\n",
    "        api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    "        base_url=\"http://127.0.0.1:8888/v1\",\n",
    "        # base_url = \"https://api.moonshot.cn/v1\",\n",
    "        system_content=\"ä½ æ˜¯ Kimiï¼Œ ä½ åªä¼šä½¿ç”¨ä¸­æ–‡è¿›è¡Œå¯¹è¯ã€‚\",\n",
    "        model=\"moonshot-v1-auto\",\n",
    "        max_context_length= 20,\n",
    "        use_stream = use_stream,\n",
    "        Candidates = 1,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"è¯·è¾“å…¥ä½ çš„é—®é¢˜(è¾“å…¥ 'exit' é€€å‡º)ï¼š\\n\")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            break\n",
    "        response = chat_manager.chat(user_input)\n",
    "        if use_stream:\n",
    "            for chunk in response:\n",
    "                delta = chunk.choices[0].delta\n",
    "                if delta.content:\n",
    "                    print(delta.content, end=\"\", flush=True)\n",
    "            print(\"\\n\")\n",
    "            continue\n",
    "        print(f\"Kimi: {response.message.content}\")\n",
    "        # chat_manager.print_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moonshot AI çš„ Context Cachingï¼ˆä¸Šä¸‹æ–‡ç¼“å­˜ï¼‰æŠ€æœ¯æ˜¯ä¸€ç§é«˜æ•ˆçš„æ•°æ®ç®¡ç†æŠ€æœ¯ã€‚å®ƒå…è®¸ç³»ç»Ÿé¢„å…ˆå­˜å‚¨é‚£äº›å¯èƒ½ä¼šè¢«é¢‘ç¹è¯·æ±‚çš„å¤§é‡æ•°æ®æˆ–ä¿¡æ¯ï¼Œè¿™æ ·å½“å†æ¬¡è¯·æ±‚ç›¸åŒä¿¡æ¯æ—¶ï¼Œç³»ç»Ÿå¯ä»¥ç›´æŽ¥ä»Žç¼“å­˜ä¸­å¿«é€Ÿæä¾›ï¼Œè€Œæ— éœ€é‡æ–°è®¡ç®—æˆ–ä»ŽåŽŸå§‹æ•°æ®æºä¸­æ£€ç´¢ï¼Œä»Žè€ŒèŠ‚çœæ—¶é—´å’Œèµ„æºã€‚\n",
      "\n",
      "ä»¥ä¸‹æ˜¯å…³äºŽè¿™é¡¹æŠ€æœ¯çš„è¦ç‚¹ï¼š\n",
      "\n",
      "1. **ä»‹ç»**ï¼šä¸Šä¸‹æ–‡ç¼“å­˜æŠ€æœ¯å¯ä»¥å­˜å‚¨å¤§é‡å¯èƒ½ä¼šè¢«é¢‘ç¹è¯·æ±‚çš„æ•°æ®æˆ–ä¿¡æ¯ï¼Œä»¥ä¾¿å¿«é€Ÿæä¾›ï¼Œæ— éœ€é‡æ–°è®¡ç®—æˆ–æ£€ç´¢ã€‚\n",
      "\n",
      "2. **æ•ˆæžœ**ï¼š\n",
      "   - è´¹ç”¨æœ€é«˜é™ä½Ž90%ï¼šç‰¹åˆ«é€‚åˆé¢‘ç¹è¯·æ±‚ã€é‡å¤å¼•ç”¨å¤§é‡åˆå§‹ä¸Šä¸‹æ–‡çš„åœºæ™¯ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ•ˆçŽ‡å¹¶é™ä½Žè´¹ç”¨ã€‚\n",
      "   - é¦–Tokenå»¶è¿Ÿé™ä½Ž83%ï¼šé€šè¿‡ä¸Šä¸‹æ–‡ç¼“å­˜æŠ€æœ¯ï¼Œ128Kæ¨¡åž‹çš„è¯·æ±‚é¦–Tokenå»¶è¿Ÿå¹³å‡å¯é™è‡³5ç§’å†…ï¼Œé™ä½Žçº¦83%ã€‚\n",
      "\n",
      "3. **å¿«é€Ÿå¼€å§‹**ï¼š\n",
      "   - åˆ›å»ºCacheï¼šé€šè¿‡APIåˆ›å»ºç¼“å­˜ï¼ŒæŒ‡å®šå­˜å‚¨çš„æ•°æ®ç±»åž‹å’Œå†…å®¹ï¼Œå¹¶è®¾ç½®åˆé€‚çš„è¿‡æœŸæ—¶é—´ã€‚\n",
      "   - ä½¿ç”¨Cacheï¼šé€šè¿‡`role=\"cache\"`æ¥å¼•ç”¨å·²åˆ›å»ºå¥½çš„ç¼“å­˜ï¼Œé¿å…å°†ç¼“å­˜å†…å®¹é‡å¤æ·»åŠ è‡³è¯·æ±‚ä¸­ã€‚\n",
      "\n",
      "4. **è®¡è´¹**ï¼š\n",
      "   - Cacheèµ„æºè´¹ç”±Cacheåˆ›å»ºè´¹å’ŒCacheå­˜å‚¨è´¹ç»„æˆã€‚\n",
      "   - ä¸€æ¬¡è°ƒç”¨æ”¶è´¹åŒ…æ‹¬Cacheè°ƒç”¨æ”¶è´¹ã€ChatæœªåŒ¹é…Cacheçš„Input Tokensæ”¶è´¹å’ŒOutput Tokensæ”¶è´¹ã€‚\n",
      "\n",
      "5. **æ ‡ç­¾ç³»ç»Ÿ**ï¼šä¸Šä¸‹æ–‡ç¼“å­˜æŠ€æœ¯è¿˜å¼•å…¥äº†æ ‡ç­¾ç³»ç»Ÿï¼Œé€šè¿‡æ ‡ç­¾ç®¡ç†å’Œä½¿ç”¨Context Cacheï¼Œé™ä½Žä½¿ç”¨è¿‡ç¨‹ä¸­çš„å¿ƒæ™ºè´Ÿæ‹…ã€‚\n",
      "\n",
      "6. **åº”ç”¨åœºæ™¯**ï¼šé€‚ç”¨äºŽé—®ç­”æœºå™¨äººæä¾›å¤§é‡é¢„è®¾å†…å®¹ã€å¯¹å›ºå®šæ–‡æ¡£é›†çš„é¢‘ç¹æŸ¥è¯¢ã€å¯¹é™æ€ä»£ç åº“æˆ–çŸ¥è¯†åº“çš„å®šæœŸåˆ†æžã€æµé‡å·¨å¤§çš„å³æ—¶çƒ­é—¨AIåº”ç”¨ï¼Œä»¥åŠå…·æœ‰å¤æ‚äº¤äº’è§„åˆ™çš„ä»£ç†åž‹åº”ç”¨ã€‚\n",
      "\n",
      "7. **å…¬æµ‹æ—¶é—´å’Œèµ„æ ¼**ï¼šåŠŸèƒ½ä¸Šçº¿åŽï¼Œå…¬æµ‹3ä¸ªæœˆï¼Œå…¬æµ‹æœŸä»·æ ¼å¯èƒ½éšæ—¶è°ƒæ•´ã€‚å…¬æµ‹æœŸé—´Context CachingåŠŸèƒ½ä»…å¼€æ”¾ç»™Tier5ç­‰çº§ç”¨æˆ·ã€‚\n",
      "\n",
      "ä¸Šä¸‹æ–‡ç¼“å­˜æŠ€æœ¯çš„åº”ç”¨å¯ä»¥æ˜¾è‘—é™ä½Žæˆæœ¬ã€æé«˜æ•ˆçŽ‡ï¼Œå¹¶ä¸ºå„ç§åº”ç”¨åœºæ™¯æä¾›æ›´å¥½çš„æœåŠ¡å’Œä½“éªŒã€‚éšç€æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œå®Œå–„ï¼Œç›¸ä¿¡è¿™é¡¹åŠŸèƒ½å°†åœ¨æœªæ¥å‘æŒ¥æ›´åŠ é‡è¦çš„ä½œç”¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "from typing import *\n",
    " \n",
    "import os\n",
    "import json\n",
    " \n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion import Choice\n",
    " \n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.moonshot.cn/v1\",\n",
    "    api_key=\"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    ")\n",
    " \n",
    " \n",
    "def search_impl(arguments: Dict[str, Any]) -> Any:\n",
    "    return arguments\n",
    " \n",
    " \n",
    "def chat(messages) -> Choice:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"moonshot-v1-128k\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        tools=[\n",
    "            {\n",
    "                \"type\": \"builtin_function\",  # <-- ä½¿ç”¨ builtin_function å£°æ˜Ž $web_search å‡½æ•°ï¼Œè¯·åœ¨æ¯æ¬¡è¯·æ±‚éƒ½å®Œæ•´åœ°å¸¦ä¸Š tools å£°æ˜Ž\n",
    "                \"function\": {\n",
    "                    \"name\": \"$web_search\",\n",
    "                },\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0]\n",
    " \n",
    " \n",
    "def main():\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ Kimiã€‚\"},\n",
    "    ]\n",
    " \n",
    "    # åˆå§‹æé—®\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"è¯·æœç´¢ Moonshot AI Context Caching æŠ€æœ¯ï¼Œå¹¶å‘Šè¯‰æˆ‘å®ƒæ˜¯ä»€ä¹ˆã€‚\"\n",
    "    })\n",
    " \n",
    "    finish_reason = None\n",
    "    while finish_reason is None or finish_reason == \"tool_calls\":\n",
    "        choice = chat(messages)\n",
    "        finish_reason = choice.finish_reason\n",
    "        if finish_reason == \"tool_calls\":  # <-- åˆ¤æ–­å½“å‰è¿”å›žå†…å®¹æ˜¯å¦åŒ…å« tool_calls\n",
    "            messages.append(choice.message)  # <-- æˆ‘ä»¬å°† Kimi å¤§æ¨¡åž‹è¿”å›žç»™æˆ‘ä»¬çš„ assistant æ¶ˆæ¯ä¹Ÿæ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼Œä»¥ä¾¿äºŽä¸‹æ¬¡è¯·æ±‚æ—¶ Kimi å¤§æ¨¡åž‹èƒ½ç†è§£æˆ‘ä»¬çš„è¯‰æ±‚\n",
    "            for tool_call in choice.message.tool_calls:  # <-- tool_calls å¯èƒ½æ˜¯å¤šä¸ªï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨å¾ªçŽ¯é€ä¸ªæ‰§è¡Œ\n",
    "                tool_call_name = tool_call.function.name\n",
    "                tool_call_arguments = json.loads(tool_call.function.arguments)  # <-- arguments æ˜¯åºåˆ—åŒ–åŽçš„ JSON Objectï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ json.loads ååºåˆ—åŒ–ä¸€ä¸‹\n",
    "                if tool_call_name == \"$web_search\":\n",
    "                    tool_result = search_impl(tool_call_arguments)\n",
    "                else:\n",
    "                    tool_result = f\"Error: unable to find tool by name '{tool_call_name}'\"\n",
    " \n",
    "                # ä½¿ç”¨å‡½æ•°æ‰§è¡Œç»“æžœæž„é€ ä¸€ä¸ª role=tool çš„ messageï¼Œä»¥æ­¤æ¥å‘æ¨¡åž‹å±•ç¤ºå·¥å…·è°ƒç”¨çš„ç»“æžœï¼›\n",
    "                # æ³¨æ„ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ message ä¸­æä¾› tool_call_id å’Œ name å­—æ®µï¼Œä»¥ä¾¿ Kimi å¤§æ¨¡åž‹\n",
    "                # èƒ½æ­£ç¡®åŒ¹é…åˆ°å¯¹åº”çš„ tool_callã€‚\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_call_name,\n",
    "                    \"content\": json.dumps(tool_result),  # <-- æˆ‘ä»¬çº¦å®šä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼å‘ Kimi å¤§æ¨¡åž‹æäº¤å·¥å…·è°ƒç”¨ç»“æžœï¼Œå› æ­¤åœ¨è¿™é‡Œä½¿ç”¨ json.dumps å°†æ‰§è¡Œç»“æžœåºåˆ—åŒ–æˆå­—ç¬¦ä¸²\n",
    "                })\n",
    " \n",
    "    print(choice.message.content)  # <-- åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æ‰å°†æ¨¡åž‹ç”Ÿæˆçš„å›žå¤è¿”å›žç»™ç”¨æˆ·\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-å·¥å…·è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI(\n",
    "    api_key = \"sk-b09XXwR8nOmrdoXTrylErTOJ0mWQYxKsRZBLMmfCiV2K0grF\",\n",
    "    base_url = \"https://api.moonshot.cn/v1\",\n",
    ")\n",
    "\n",
    "tool = [\n",
    "    {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": \"CodeRunner\",\n",
    "        \"description\": \"ä»£ç æ‰§è¡Œå™¨ï¼Œæ”¯æŒè¿è¡Œ python å’Œ javascript ä»£ç \",\n",
    "        \"parameters\": {\n",
    "          \"properties\": {\n",
    "            \"language\": {\n",
    "              \"type\": \"string\",\n",
    "              \"enum\": [\"python\", \"javascript\"]\n",
    "            },\n",
    "            \"code\": {\n",
    "              \"type\": \"string\",\n",
    "              \"description\": \"ä»£ç å†™åœ¨è¿™é‡Œ\"\n",
    "            }\n",
    "          },\n",
    "          \"type\": \"object\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": \"def is_prime(n):\\n    if n <= 1:\\n        return False\\n    if n <= 3:\\n        return True\\n    if n % 2 == 0 or n % 3 == 0:\\n        return False\\n    i = 5\\n    while i * i <= n:\\n        if n % i == 0 or n % (i + 2) == 0:\\n            return False\\n        i += 6\\n    return True\\n\\n# æ£€æŸ¥ 3214567 æ˜¯å¦æ˜¯ç´ æ•°\\nnumber_to_check = 3214567\\nis_prime(number_to_check)\",\n",
      "    \"language\": \"python\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"ä½ æ˜¯ Kimiï¼Œç”± Moonshot AI æä¾›çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œä½ æ›´æ“…é•¿ä¸­æ–‡å’Œè‹±æ–‡çš„å¯¹è¯ã€‚ä½ ä¼šä¸ºç”¨æˆ·æä¾›å®‰å…¨ï¼Œæœ‰å¸®åŠ©ï¼Œå‡†ç¡®çš„å›žç­”ã€‚åŒæ—¶ï¼Œä½ ä¼šæ‹’ç»ä¸€äº›æ¶‰åŠææ€–ä¸»ä¹‰ï¼Œç§æ—æ­§è§†ï¼Œé»„è‰²æš´åŠ›ç­‰é—®é¢˜çš„å›žç­”ã€‚Moonshot AI ä¸ºä¸“æœ‰åè¯ï¼Œä¸å¯ç¿»è¯‘æˆå…¶ä»–è¯­è¨€ã€‚\"},\n",
    "        {\"role\": \"user\", \"content\": \"ç¼–ç¨‹åˆ¤æ–­ 3214567 æ˜¯å¦æ˜¯ç´ æ•°ã€‚\"}\n",
    "    ],\n",
    "    tools = tool,\n",
    "    temperature=0.3,\n",
    ")\n",
    "print(completion.choices[0].message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12356\\3251451039.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompletion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "completion.choices[0].message.tool_calls[0].function.arguments[\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
